import streamlit as st
from agno.agent import Agent, RunEvent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.url import UrlKnowledge
from agno.models.anthropic import Claude
from agno.tools.reasoning import ReasoningTools
from agno.vectordb.lancedb import LanceDb, SearchType
from dotenv import load_dotenv
import os

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¸¦æ¨ç†åŠŸèƒ½çš„æ™ºèƒ½ä½“é©±åŠ¨å‹RAGç³»ç»Ÿ",
    page_icon="ğŸ§",
    layout="wide"
)

# ä¸»æ ‡é¢˜å’Œè¯´æ˜
st.title("ğŸ§ å¸¦æ¨ç†åŠŸèƒ½çš„æ™ºèƒ½ä½“é©±åŠ¨å‹RAGç³»ç»Ÿ")
st.markdown("""
æœ¬åº”ç”¨å±•ç¤ºäº†ä¸€ä¸ªAIæ™ºèƒ½ä½“ï¼Œå®ƒèƒ½å¤Ÿï¼š
1. **æ£€ç´¢**ï¼šä»çŸ¥è¯†æºä¸­è·å–ç›¸å…³ä¿¡æ¯
2. **æ¨ç†**ï¼šé€æ­¥åˆ†æä¿¡æ¯
3. **å›ç­”**ï¼šé™„å¸¦å¼•ç”¨åœ°è§£ç­”æ‚¨çš„é—®é¢˜

åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„APIå¯†é’¥å³å¯å¼€å§‹ä½¿ç”¨ï¼
""")

# APIå¯†é’¥éƒ¨åˆ†
st.subheader("ğŸ”‘ APIå¯†é’¥")
col1, col2 = st.columns(2)
with col1:
    anthropic_key = st.text_input(
        "Anthropic APIå¯†é’¥",
        type="password",
        value=os.getenv("ANTHROPIC_API_KEY", ""),
        help="ä»https://console.anthropic.com/è·å–æ‚¨çš„å¯†é’¥"
    )
with col2:
    openai_key = st.text_input(
        "OpenAI APIå¯†é’¥",
        type="password",
        value=os.getenv("OPENAI_API_KEY", ""),
        help="ä»https://platform.openai.com/è·å–æ‚¨çš„å¯†é’¥"
    )

# æ£€æŸ¥æ˜¯å¦æä¾›äº†APIå¯†é’¥
if anthropic_key and openai_key:

    # åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆç¼“å­˜ä»¥é¿å…é‡å¤åŠ è½½ï¼‰
    @st.cache_resource(show_spinner="ğŸ“š æ­£åœ¨åŠ è½½çŸ¥è¯†åº“...")
    def load_knowledge() -> UrlKnowledge:
        """åŠ è½½å¹¶åˆå§‹åŒ–å¸¦æœ‰å‘é‡æ•°æ®åº“çš„çŸ¥è¯†åº“"""
        kb = UrlKnowledge(
            urls=["https://docs.agno.com/introduction/agents.md"],  # é»˜è®¤URL
            vector_db=LanceDb(
                uri="tmp/lancedb",
                table_name="agno_docs",
                search_type=SearchType.vector,  # ä½¿ç”¨å‘é‡æœç´¢
                embedder=OpenAIEmbedder(
                    api_key=openai_key
                ),
            ),
        )
        kb.load(recreate=True)  # å°†æ–‡æ¡£åŠ è½½åˆ°å‘é‡æ•°æ®åº“
        return kb


    # åˆå§‹åŒ–æ™ºèƒ½ä½“ï¼ˆç¼“å­˜ä»¥é¿å…é‡å¤åŠ è½½ï¼‰
    @st.cache_resource(show_spinner="ğŸ¤– æ­£åœ¨åŠ è½½æ™ºèƒ½ä½“...")
    def load_agent(_kb: UrlKnowledge) -> Agent:
        """åˆ›å»ºå…·æœ‰æ¨ç†èƒ½åŠ›çš„æ™ºèƒ½ä½“"""
        return Agent(
            model=Claude(
                id="claude-sonnet-4-20250514",
                api_key=anthropic_key
            ),
            knowledge=_kb,
            search_knowledge=True,  # å¯ç”¨çŸ¥è¯†æœç´¢
            tools=[ReasoningTools(add_instructions=True)],  # æ·»åŠ æ¨ç†å·¥å…·
            instructions=[
                "åœ¨å›ç­”ä¸­åŒ…å«æ¥æºå¼•ç”¨ã€‚",
                "å›ç­”é—®é¢˜å‰åŠ¡å¿…å…ˆæœç´¢çŸ¥è¯†åº“ã€‚",
            ],
            markdown=True,  # å¯ç”¨markdownæ ¼å¼
        )


    # åŠ è½½çŸ¥è¯†å’Œæ™ºèƒ½ä½“
    knowledge = load_knowledge()
    agent = load_agent(knowledge)

    # ä¾§è¾¹æ ç”¨äºçŸ¥è¯†ç®¡ç†
    with st.sidebar:
        st.header("ğŸ“š çŸ¥è¯†æ¥æº")
        st.markdown("æ·»åŠ URLä»¥æ‰©å±•çŸ¥è¯†åº“ï¼š")

        # æ˜¾ç¤ºå½“å‰URL
        st.write("**å½“å‰æ¥æºï¼š**")
        for i, url in enumerate(knowledge.urls):
            st.text(f"{i + 1}. {url}")

        # æ·»åŠ æ–°URL
        st.divider()
        new_url = st.text_input(
            "æ·»åŠ æ–°URL",
            placeholder="https://example.com/docs",
            help="è¾“å…¥è¦æ·»åŠ åˆ°çŸ¥è¯†åº“çš„URL"
        )

        if st.button("â• æ·»åŠ URL", type="primary"):
            if new_url:
                with st.spinner("ğŸ“¥ æ­£åœ¨åŠ è½½æ–°æ–‡æ¡£..."):
                    knowledge.urls.append(new_url)
                    knowledge.load(
                        recreate=False,  # ä¸é‡å»ºæ•°æ®åº“
                        upsert=True,  # æ›´æ–°ç°æœ‰æ–‡æ¡£
                        skip_existing=True  # è·³è¿‡å·²åŠ è½½çš„æ–‡æ¡£
                    )
                st.success(f"âœ… å·²æ·»åŠ ï¼š{new_url}")
                st.rerun()  # åˆ·æ–°ä»¥æ˜¾ç¤ºæ–°URL
            else:
                st.error("è¯·è¾“å…¥URL")

    # ä¸»æŸ¥è¯¢éƒ¨åˆ†
    st.divider()
    st.subheader("ğŸ¤” æå‡ºé—®é¢˜")

    # æŸ¥è¯¢è¾“å…¥
    query = st.text_area(
        "æ‚¨çš„é—®é¢˜ï¼š",
        value="ä»€ä¹ˆæ˜¯æ™ºèƒ½ä½“ï¼ˆAgentsï¼‰ï¼Ÿ",
        height=100,
        help="è¯¢é—®æœ‰å…³å·²åŠ è½½çŸ¥è¯†æ¥æºçš„ä»»ä½•é—®é¢˜"
    )

    # è¿è¡ŒæŒ‰é’®
    if st.button("ğŸš€ è·å–å¸¦æ¨ç†è¿‡ç¨‹çš„ç­”æ¡ˆ", type="primary"):
        if query:
            # åˆ›å»ºç”¨äºæµå¼æ›´æ–°çš„å®¹å™¨
            col1, col2 = st.columns([1, 1])

            with col1:
                st.markdown("### ğŸ§  æ¨ç†è¿‡ç¨‹")
                reasoning_container = st.container()
                reasoning_placeholder = reasoning_container.empty()

            with col2:
                st.markdown("### ğŸ’¡ ç­”æ¡ˆ")
                answer_container = st.container()
                answer_placeholder = answer_container.empty()

            # ç”¨äºç´¯ç§¯å†…å®¹çš„å˜é‡
            citations = []
            answer_text = ""
            reasoning_text = ""

            # æµå¼ä¼ è¾“æ™ºèƒ½ä½“çš„å“åº”
            with st.spinner("ğŸ” æ­£åœ¨æœç´¢å’Œæ¨ç†..."):
                for chunk in agent.run(
                        query,
                        stream=True,  # å¯ç”¨æµå¼ä¼ è¾“
                        show_full_reasoning=True,  # æ˜¾ç¤ºæ¨ç†æ­¥éª¤
                        stream_intermediate_steps=True,  # æµå¼ä¼ è¾“ä¸­é—´æ›´æ–°
                ):
                    # æ›´æ–°æ¨ç†è¿‡ç¨‹æ˜¾ç¤º
                    if chunk.reasoning_content:
                        reasoning_text = chunk.reasoning_content
                        reasoning_placeholder.markdown(
                            reasoning_text,
                            unsafe_allow_html=True
                        )

                    # æ›´æ–°ç­”æ¡ˆæ˜¾ç¤º
                    if chunk.content and chunk.event in {RunEvent.run_response, RunEvent.run_completed}:
                        if isinstance(chunk.content, str):
                            answer_text += chunk.content
                            answer_placeholder.markdown(
                                answer_text,
                                unsafe_allow_html=True
                            )

                    # æ”¶é›†å¼•ç”¨
                    if chunk.citations and chunk.citations.urls:
                        citations = chunk.citations.urls

            # å¦‚æœæœ‰å¼•ç”¨ï¼Œæ˜¾ç¤ºå¼•ç”¨
            if citations:
                st.divider()
                st.subheader("ğŸ“š æ¥æº")
                for cite in citations:
                    title = cite.title or cite.url
                    st.markdown(f"- [{title}]({cite.url})")
        else:
            st.error("è¯·è¾“å…¥é—®é¢˜")

else:
    # å¦‚æœç¼ºå°‘APIå¯†é’¥ï¼Œæ˜¾ç¤ºè¯´æ˜
    st.info("""
    ğŸ‘‹ **æ¬¢è¿ï¼è¦ä½¿ç”¨æ­¤åº”ç”¨ï¼Œæ‚¨éœ€è¦ï¼š**

    1. **Anthropic APIå¯†é’¥** - ç”¨äºClaude AIæ¨¡å‹
       - åœ¨[console.anthropic.com](https://console.anthropic.com/)æ³¨å†Œ

    2. **OpenAI APIå¯†é’¥** - ç”¨äºåµŒå…¥ç”Ÿæˆ
       - åœ¨[platform.openai.com](https://platform.openai.com/)æ³¨å†Œ

    è·å¾—è¿™ä¸¤ä¸ªå¯†é’¥åï¼Œåœ¨ä¸Šæ–¹è¾“å…¥å³å¯å¼€å§‹ä½¿ç”¨ï¼
    """)

# å¸¦è§£é‡Šçš„é¡µè„š
st.divider()
with st.expander("ğŸ“– å·¥ä½œåŸç†"):
    st.markdown("""
    **æœ¬åº”ç”¨ä½¿ç”¨Agnoæ¡†æ¶åˆ›å»ºæ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼š**

    1. **çŸ¥è¯†åŠ è½½**ï¼šURLè¢«å¤„ç†å¹¶å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ï¼ˆLanceDBï¼‰ä¸­
    2. **å‘é‡æœç´¢**ï¼šä½¿ç”¨OpenAIçš„åµŒå…¥è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œä»¥æ‰¾åˆ°ç›¸å…³ä¿¡æ¯
    3. **æ¨ç†å·¥å…·**ï¼šæ™ºèƒ½ä½“ä½¿ç”¨ç‰¹æ®Šå·¥å…·é€æ­¥æ€è€ƒé—®é¢˜
    4. **Claude AI**ï¼šAnthropicçš„Claudeæ¨¡å‹å¤„ç†ä¿¡æ¯å¹¶ç”Ÿæˆç­”æ¡ˆ

    **æ ¸å¿ƒç»„ä»¶ï¼š**
    - `UrlKnowledge`ï¼šç®¡ç†ä»URLåŠ è½½æ–‡æ¡£
    - `LanceDb`ï¼šç”¨äºé«˜æ•ˆç›¸ä¼¼æ€§æœç´¢çš„å‘é‡æ•°æ®åº“
    - `OpenAIEmbedder`ï¼šä½¿ç”¨OpenAIçš„åµŒå…¥æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºåµŒå…¥
    - `ReasoningTools`ï¼šæ”¯æŒé€æ­¥æ¨ç†
    - `Agent`ï¼šåè°ƒæ‰€æœ‰å·¥ä½œä»¥å›ç­”é—®é¢˜
    """)