import os
import logging
import streamlit as st
from raglite import RAGLiteConfig, insert_document, hybrid_search, retrieve_chunks, rerank_chunks, rag
from rerankers import Reranker
from typing import List
from pathlib import Path
import anthropic
import time
import warnings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore", message=".*torch.classes.*")

RAG_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªå‹å¥½ä¸”çŸ¥è¯†æ¸Šåšçš„åŠ©æ‰‹ï¼Œèƒ½æä¾›å®Œæ•´ä¸”æœ‰æ´å¯ŸåŠ›çš„ç­”æ¡ˆã€‚
ä»…ä½¿ç”¨ä¸‹é¢çš„ä¸Šä¸‹æ–‡æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å›ç­”æ—¶ï¼Œä¸¥ç¦ç›´æ¥æˆ–é—´æ¥æåŠä¸Šä¸‹æ–‡çš„å­˜åœ¨ã€‚
ç›¸åï¼Œä½ å¿…é¡»å°†ä¸Šä¸‹æ–‡çš„å†…å®¹è§†ä¸ºå®Œå…¨æ˜¯ä½ å·¥ä½œè®°å¿†çš„ä¸€éƒ¨åˆ†ã€‚
""".strip()


def initialize_config(openai_key: str, anthropic_key: str, cohere_key: str, db_url: str) -> RAGLiteConfig:
    """åˆå§‹åŒ–å¹¶è¿”å›ä¸€ä¸ªå¸¦æœ‰æŒ‡å®šAPIå¯†é’¥å’Œæ•°æ®åº“URLçš„RAGLiteConfigå¯¹è±¡ã€‚

    æ­¤å‡½æ•°å°†æä¾›çš„APIå¯†é’¥è®¾ç½®åœ¨ç¯å¢ƒå˜é‡ä¸­ï¼Œå¹¶è¿”å›ä¸€ä¸ª
    ç”¨ç»™å®šçš„æ•°æ®åº“URLå’Œé¢„å®šä¹‰çš„è¯­è¨€æ¨¡å‹ã€åµŒå…¥å™¨å’Œé‡æ’åºå™¨è®¾ç½®é…ç½®çš„RAGLiteConfigå¯¹è±¡ã€‚

    å‚æ•°:
        openai_key (str): OpenAIæœåŠ¡çš„APIå¯†é’¥ã€‚
        anthropic_key (str): AnthropicæœåŠ¡çš„APIå¯†é’¥ã€‚
        cohere_key (str): CohereæœåŠ¡çš„APIå¯†é’¥ã€‚
        db_url (str): ç”¨äºè¿æ¥åˆ°æ‰€éœ€æ•°æ®æºçš„æ•°æ®åº“URLã€‚

    è¿”å›:
        RAGLiteConfig: ç”¨æŒ‡å®šå‚æ•°åˆå§‹åŒ–çš„é…ç½®å¯¹è±¡ã€‚

    å¼‚å¸¸:
        ValueError: å¦‚æœåœ¨è®¾ç½®é…ç½®æ—¶å‡ºç°é—®é¢˜ï¼Œå°†å¼•å‘å¸¦æœ‰è¯¦ç»†ä¿¡æ¯çš„é”™è¯¯ã€‚"""
    try:
        os.environ["OPENAI_API_KEY"] = openai_key
        os.environ["ANTHROPIC_API_KEY"] = anthropic_key
        os.environ["COHERE_API_KEY"] = cohere_key

        return RAGLiteConfig(
            db_url=db_url,
            llm="claude-3-opus-20240229",
            embedder="text-embedding-3-large",
            embedder_normalize=True,
            chunk_max_size=2000,
            embedder_sentence_window_size=2,
            reranker=Reranker("cohere", api_key=cohere_key, lang="en")
        )
    except Exception as e:
        raise ValueError(f"é…ç½®é”™è¯¯: {e}")


def process_document(file_path: str) -> bool:
    """é€šè¿‡å°†æ–‡æ¡£æ’å…¥åˆ°å…·æœ‰ç»™å®šé…ç½®çš„ç³»ç»Ÿä¸­æ¥å¤„ç†æ–‡æ¡£ã€‚

    æ­¤å‡½æ•°æ£€æŸ¥ä¼šè¯çŠ¶æ€ä¸­æ˜¯å¦åˆå§‹åŒ–äº†é…ç½®ã€‚
    å¦‚æœé…ç½®å­˜åœ¨ï¼Œå®ƒä¼šå°è¯•ä½¿ç”¨æ­¤é…ç½®æ’å…¥ä½äºç»™å®šæ–‡ä»¶è·¯å¾„çš„æ–‡æ¡£ã€‚

    å‚æ•°:
        file_path (str): è¦å¤„ç†çš„æ–‡æ¡£çš„è·¯å¾„ã€‚

    è¿”å›:
        bool: å¦‚æœæ–‡æ¡£æˆåŠŸå¤„ç†åˆ™ä¸ºTrueï¼›å¦åˆ™ä¸ºFalseã€‚"""
    try:
        if not st.session_state.get('my_config'):
            raise ValueError("é…ç½®æœªåˆå§‹åŒ–")
        insert_document(Path(file_path), config=st.session_state.my_config)
        return True
    except Exception as e:
        logger.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
        return False


def perform_search(query: str) -> List[dict]:
    """æ‰§è¡Œæ··åˆæœç´¢å¹¶è¿”å›åŸºäºæŸ¥è¯¢çš„æ’åºåçš„å—åˆ—è¡¨ã€‚

    æ­¤å‡½æ•°ä½¿ç”¨æ··åˆæœç´¢æ–¹æ³•æ‰§è¡Œæœç´¢ï¼Œæ£€ç´¢ç›¸å…³å—ï¼Œå¹¶æ ¹æ®æŸ¥è¯¢å¯¹å®ƒä»¬è¿›è¡Œé‡æ’åºã€‚
    å®ƒå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿçš„ä»»ä½•å¼‚å¸¸å¹¶è®°å½•é”™è¯¯ã€‚

    å‚æ•°:
        query (str): æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚

    è¿”å›:
        List[dict]: è¡¨ç¤ºæ’åºåå—çš„å­—å…¸åˆ—è¡¨ã€‚å¦‚æœæœªæ‰¾åˆ°ç»“æœæˆ–å‘ç”Ÿé”™è¯¯ï¼Œåˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚"""
    try:
        chunk_ids, scores = hybrid_search(query, num_results=10, config=st.session_state.my_config)
        if not chunk_ids:
            return []
        chunks = retrieve_chunks(chunk_ids, config=st.session_state.my_config)
        return rerank_chunks(query, chunks, config=st.session_state.my_config)
    except Exception as e:
        logger.error(f"æœç´¢é”™è¯¯: {str(e)}")
        return []


def handle_fallback(query: str) -> str:
    try:
        client = anthropic.Anthropic(api_key=st.session_state.user_env["ANTHROPIC_API_KEY"])
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚å½“ä½ ä¸çŸ¥é“æŸäº›äº‹æƒ…æ—¶ï¼Œè¦è¯šå®åœ°è¯´æ˜ã€‚
        æä¾›æ¸…æ™°ã€ç®€æ´å’Œå‡†ç¡®çš„å›åº”ã€‚å¦‚æœé—®é¢˜ä¸ä»»ä½•ç‰¹å®šæ–‡æ¡£æ— å…³ï¼Œè¯·ä½¿ç”¨ä½ çš„å¸¸è¯†æ¥å›ç­”ã€‚"""

        message = client.messages.create(
            model="claude-3-sonnet-20240229",
            max_tokens=1024,
            system=system_prompt,
            messages=[{"role": "user", "content": query}],
            temperature=0.7
        )
        return message.content[0].text
    except Exception as e:
        logger.error(f"å¤‡ç”¨å¤„ç†é”™è¯¯: {str(e)}")
        st.error(f"å¤‡ç”¨å¤„ç†é”™è¯¯: {str(e)}")  # åœ¨UIä¸­æ˜¾ç¤ºé”™è¯¯
        return "æŠ±æ­‰ï¼Œå¤„ç†ä½ çš„è¯·æ±‚æ—¶é‡åˆ°é”™è¯¯ã€‚è¯·é‡è¯•ã€‚"


def main():
    st.set_page_config(page_title="LLMé©±åŠ¨çš„æ··åˆæœç´¢-RAGåŠ©æ‰‹", layout="wide")

    for state_var in ['chat_history', 'documents_loaded', 'my_config', 'user_env']:
        if state_var not in st.session_state:
            st.session_state[
                state_var] = [] if state_var == 'chat_history' else False if state_var == 'documents_loaded' else None if state_var == 'my_config' else {}

    with st.sidebar:
        st.title("é…ç½®")
        openai_key = st.text_input("OpenAI APIå¯†é’¥", value=st.session_state.get('openai_key', ''), type="password",
                                   placeholder="sk-...")
        anthropic_key = st.text_input("Anthropic APIå¯†é’¥", value=st.session_state.get('anthropic_key', ''),
                                      type="password", placeholder="sk-ant-...")
        cohere_key = st.text_input("Cohere APIå¯†é’¥", value=st.session_state.get('cohere_key', ''), type="password",
                                   placeholder="è¾“å…¥Cohereå¯†é’¥")
        db_url = st.text_input("æ•°æ®åº“URL", value=st.session_state.get('db_url', 'sqlite:///raglite.sqlite'),
                               placeholder="sqlite:///raglite.sqlite")

        if st.button("ä¿å­˜é…ç½®"):
            try:
                if not all([openai_key, anthropic_key, cohere_key, db_url]):
                    st.error("æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¿…å¡«çš„ï¼")
                    return

                for key, value in {'openai_key': openai_key, 'anthropic_key': anthropic_key, 'cohere_key': cohere_key,
                                   'db_url': db_url}.items():
                    st.session_state[key] = value

                st.session_state.my_config = initialize_config(openai_key=openai_key, anthropic_key=anthropic_key,
                                                               cohere_key=cohere_key, db_url=db_url)
                st.session_state.user_env = {"ANTHROPIC_API_KEY": anthropic_key}
                st.success("é…ç½®ä¿å­˜æˆåŠŸï¼")
            except Exception as e:
                st.error(f"é…ç½®é”™è¯¯: {str(e)}")

    st.title("ğŸ‘€ å¸¦æœ‰æ··åˆæœç´¢çš„RAGåº”ç”¨")

    if st.session_state.my_config:
        uploaded_files = st.file_uploader("ä¸Šä¼ PDFæ–‡æ¡£", type=["pdf"], accept_multiple_files=True, key="pdf_uploader")

        if uploaded_files:
            success = False
            for uploaded_file in uploaded_files:
                with st.spinner(f"æ­£åœ¨å¤„ç† {uploaded_file.name}..."):
                    temp_path = f"temp_{uploaded_file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.getvalue())

                    if process_document(temp_path):
                        st.success(f"æˆåŠŸå¤„ç†: {uploaded_file.name}")
                        success = True
                    else:
                        st.error(f"å¤„ç†å¤±è´¥: {uploaded_file.name}")
                    os.remove(temp_path)

            if success:
                st.session_state.documents_loaded = True
                st.success("æ–‡æ¡£å·²å‡†å¤‡å°±ç»ªï¼ç°åœ¨ä½ å¯ä»¥è¯¢é—®æœ‰å…³å®ƒä»¬çš„é—®é¢˜äº†ã€‚")

    if st.session_state.documents_loaded:
        for msg in st.session_state.chat_history:
            with st.chat_message("user"): st.write(msg[0])
            with st.chat_message("assistant"): st.write(msg[1])

        user_input = st.chat_input("è¯¢é—®æœ‰å…³æ–‡æ¡£çš„é—®é¢˜...")
        if user_input:
            with st.chat_message("user"):
                st.write(user_input)
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                try:
                    reranked_chunks = perform_search(query=user_input)
                    if not reranked_chunks or len(reranked_chunks) == 0:
                        logger.info("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚åˆ‡æ¢åˆ°Claudeã€‚")
                        st.info("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚ä½¿ç”¨å¸¸è¯†æ¥å›ç­”ã€‚")
                        full_response = handle_fallback(user_input)
                    else:
                        formatted_messages = [{"role": "user" if i % 2 == 0 else "assistant", "content": msg}
                                              for i, msg in
                                              enumerate([m for pair in st.session_state.chat_history for m in pair]) if
                                              msg]

                        response_stream = rag(prompt=user_input,
                                              system_prompt=RAG_SYSTEM_PROMPT,
                                              search=hybrid_search,
                                              messages=formatted_messages,
                                              max_contexts=5,
                                              config=st.session_state.my_config)

                        full_response = ""
                        for chunk in response_stream:
                            full_response += chunk
                            message_placeholder.markdown(full_response + "â–Œ")

                    message_placeholder.markdown(full_response)
                    st.session_state.chat_history.append((user_input, full_response))
                except Exception as e:
                    st.error(f"é”™è¯¯: {str(e)}")
    else:
        st.info("è¯·é…ç½®ä½ çš„APIå¯†é’¥å¹¶ä¸Šä¼ æ–‡æ¡£ä»¥å¼€å§‹ä½¿ç”¨ã€‚" if not st.session_state.my_config else "è¯·ä¸Šä¼ ä¸€äº›æ–‡æ¡£ä»¥å¼€å§‹ä½¿ç”¨ã€‚")


if __name__ == "__main__":
    main()