import os
import logging
import streamlit as st
from raglite import RAGLiteConfig, insert_document, hybrid_search, retrieve_chunks, rerank_chunks, rag
from rerankers import Reranker
from typing import List, Dict, Any
from pathlib import Path
import time
import warnings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore", message=".*torch.classes.*")

RAG_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªå‹å¥½ä¸”çŸ¥è¯†æ¸Šåšçš„åŠ©æ‰‹ï¼Œèƒ½æä¾›å®Œæ•´ä¸”æœ‰æ´å¯ŸåŠ›çš„ç­”æ¡ˆã€‚
ä»…ä½¿ç”¨ä¸‹é¢çš„ä¸Šä¸‹æ–‡æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å›ç­”æ—¶ï¼Œä¸¥ç¦ç›´æ¥æˆ–é—´æ¥æåŠä¸Šä¸‹æ–‡çš„å­˜åœ¨ã€‚
ç›¸åï¼Œä½ å¿…é¡»å°†ä¸Šä¸‹æ–‡çš„å†…å®¹è§†ä¸ºå®Œå…¨æ˜¯ä½ å·¥ä½œè®°å¿†çš„ä¸€éƒ¨åˆ†ã€‚
""".strip()


def initialize_config(settings: Dict[str, Any]) -> RAGLiteConfig:
    """åŸºäºæä¾›çš„è®¾ç½®åˆå§‹åŒ–å¹¶è¿”å›RAGLiteConfigå¯¹è±¡ã€‚

    æ­¤å‡½æ•°ä½¿ç”¨`settings`å­—å…¸ä¸­æŒ‡å®šçš„æ•°æ®åº“URLã€è¯­è¨€æ¨¡å‹è·¯å¾„å’ŒåµŒå…¥å™¨è·¯å¾„æ„å»ºRAGLiteConfigå¯¹è±¡ã€‚
    é…ç½®åŒ…æ‹¬åµŒå…¥å™¨å½’ä¸€åŒ–å’Œå—å¤§å°çš„é»˜è®¤é€‰é¡¹ã€‚é‡æ’åºå™¨ä¹Ÿä½¿ç”¨é¢„å®šä¹‰æ¨¡å‹åˆå§‹åŒ–ã€‚

    å‚æ•°:
        settings (Dict[str, Any]): åŒ…å«é…ç½®å‚æ•°çš„å­—å…¸ã€‚é¢„æœŸçš„é”®æ˜¯'DBUrl'ã€'LLMPath'å’Œ'EmbedderPath'ã€‚

    è¿”å›:
        RAGLiteConfig: RAGLiteçš„åˆå§‹åŒ–é…ç½®å¯¹è±¡ã€‚

    å¼‚å¸¸:
        ValueError: å¦‚æœé…ç½®è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œä¾‹å¦‚è®¾ç½®å­—å…¸ä¸­ç¼ºå°‘é”®æˆ–å€¼æ— æ•ˆã€‚"""
    try:
        return RAGLiteConfig(
            db_url=settings["DBUrl"],
            llm=f"llama-cpp-python/{settings['LLMPath']}",
            embedder=f"llama-cpp-python/{settings['EmbedderPath']}",
            embedder_normalize=True,
            chunk_max_size=512,
            reranker=Reranker("ms-marco-MiniLM-L-12-v2", model_type="flashrank")
        )
    except Exception as e:
        raise ValueError(f"é…ç½®é”™è¯¯: {e}")


def process_document(file_path: str) -> bool:
    """é€šè¿‡å°†æ–‡æ¡£æ’å…¥å…·æœ‰ç»™å®šé…ç½®çš„ç³»ç»Ÿæ¥å¤„ç†æ–‡æ¡£ã€‚

    æ­¤å‡½æ•°å°è¯•ä½¿ç”¨å­˜å‚¨åœ¨ä¼šè¯çŠ¶æ€ä¸­çš„é¢„å®šä¹‰é…ç½®ï¼Œå°†æ–‡ä»¶è·¯å¾„æŒ‡å®šçš„æ–‡æ¡£æ’å…¥åˆ°ç³»ç»Ÿä¸­ã€‚
    å¦‚æœæ“ä½œå¤±è´¥ï¼Œå®ƒä¼šè®°å½•é”™è¯¯ã€‚

    å‚æ•°:
        file_path (str): éœ€è¦å¤„ç†çš„æ–‡æ¡£æ–‡ä»¶çš„è·¯å¾„ã€‚

    è¿”å›:
        bool: å¦‚æœæ–‡æ¡£æˆåŠŸå¤„ç†åˆ™ä¸ºTrueï¼›å¦‚æœå‘ç”Ÿé”™è¯¯åˆ™ä¸ºFalseã€‚"""
    try:
        if not st.session_state.get('my_config'):
            raise ValueError("é…ç½®æœªåˆå§‹åŒ–")
        insert_document(Path(file_path), config=st.session_state.my_config)
        return True
    except Exception as e:
        logger.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
        return False


def perform_search(query: str) -> List[dict]:
    """æ‰§è¡Œæ··åˆæœç´¢å¹¶è¿”å›é‡æ–°æ’åºçš„ç»“æœã€‚

    æ­¤å‡½æ•°ä½¿ç”¨æä¾›çš„æŸ¥è¯¢æ‰§è¡Œæ··åˆæœç´¢ï¼Œå¹¶å°è¯•æ£€ç´¢å’Œé‡æ–°æ’åºç›¸å…³å—ã€‚
    å®ƒè¿”å›é‡æ–°æ’åºçš„æœç´¢ç»“æœåˆ—è¡¨ã€‚

    å‚æ•°:
        query (str): æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚

    è¿”å›:
        List[dict]: åŒ…å«é‡æ–°æ’åºçš„æœç´¢ç»“æœçš„å­—å…¸åˆ—è¡¨ã€‚
        å¦‚æœæœªæ‰¾åˆ°ç»“æœæˆ–å‘ç”Ÿé”™è¯¯ï¼Œåˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚"""
    try:
        chunk_ids, scores = hybrid_search(query, num_results=10, config=st.session_state.my_config)
        if not chunk_ids:
            return []
        chunks = retrieve_chunks(chunk_ids, config=st.session_state.my_config)
        return rerank_chunks(query, chunks, config=st.session_state.my_config)
    except Exception as e:
        logger.error(f"æœç´¢é”™è¯¯: {str(e)}")
        return []


def handle_fallback(query: str) -> str:
    try:
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚å½“ä½ ä¸çŸ¥é“æŸäº›äº‹æƒ…æ—¶ï¼Œ
        è¦è¯šå®åœ°è¯´æ˜ã€‚æä¾›æ¸…æ™°ã€ç®€æ´å’Œå‡†ç¡®çš„å›åº”ã€‚"""

        response_stream = rag(
            prompt=query,
            system_prompt=system_prompt,
            search=None,
            messages=[],
            max_tokens=1024,
            temperature=0.7,
            config=st.session_state.my_config
        )

        full_response = ""
        for chunk in response_stream:
            full_response += chunk

        if not full_response.strip():
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›åº”ã€‚è¯·å°è¯•é‡æ–°è¡¨è¿°ä½ çš„é—®é¢˜ã€‚"

        return full_response

    except Exception as e:
        logger.error(f"å¤‡ç”¨å¤„ç†é”™è¯¯: {str(e)}")
        return "æŠ±æ­‰ï¼Œå¤„ç†ä½ çš„è¯·æ±‚æ—¶é‡åˆ°é”™è¯¯ã€‚è¯·é‡è¯•ã€‚"


def main():
    st.set_page_config(page_title="æœ¬åœ°LLMé©±åŠ¨çš„æ··åˆæœç´¢-RAGåŠ©æ‰‹", layout="wide")

    for state_var in ['chat_history', 'documents_loaded', 'my_config']:
        if state_var not in st.session_state:
            st.session_state[
                state_var] = [] if state_var == 'chat_history' else False if state_var == 'documents_loaded' else None

    with st.sidebar:
        st.title("é…ç½®")

        llm_path = st.text_input(
            "LLMæ¨¡å‹è·¯å¾„",
            value=st.session_state.get('llm_path', ''),
            placeholder="TheBloke/Llama-2-7B-Chat-GGUF/llama-2-7b-chat.Q4_K_M.gguf@4096",
            help="GGUFæ ¼å¼çš„æœ¬åœ°LLMæ¨¡å‹è·¯å¾„"
        )

        embedder_path = st.text_input(
            "åµŒå…¥æ¨¡å‹è·¯å¾„",
            value=st.session_state.get('embedder_path', ''),
            placeholder="lm-kit/bge-m3-gguf/bge-m3-Q4_K_M.gguf@1024",
            help="GGUFæ ¼å¼çš„æœ¬åœ°åµŒå…¥æ¨¡å‹è·¯å¾„"
        )

        db_url = st.text_input(
            "æ•°æ®åº“URL",
            value=st.session_state.get('db_url', ''),
            placeholder="postgresql://user:pass@host:port/db",
            help="æ•°æ®åº“è¿æ¥URL"
        )

        if st.button("ä¿å­˜é…ç½®"):
            try:
                if not all([llm_path, embedder_path, db_url]):
                    st.error("æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¿…å¡«çš„ï¼")
                    return

                settings = {
                    "LLMPath": llm_path,
                    "EmbedderPath": embedder_path,
                    "DBUrl": db_url
                }

                st.session_state.my_config = initialize_config(settings)
                st.success("é…ç½®ä¿å­˜æˆåŠŸï¼")

            except Exception as e:
                st.error(f"é…ç½®é”™è¯¯: {str(e)}")

    st.title("ğŸ–¥ï¸ å¸¦æœ‰æ··åˆæœç´¢çš„æœ¬åœ°RAGåº”ç”¨")

    if st.session_state.my_config:
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ PDFæ–‡æ¡£",
            type=["pdf"],
            accept_multiple_files=True,
            key="pdf_uploader"
        )

        if uploaded_files:
            success = False
            for uploaded_file in uploaded_files:
                with st.spinner(f"æ­£åœ¨å¤„ç† {uploaded_file.name}..."):
                    temp_path = f"temp_{uploaded_file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.getvalue())

                    if process_document(temp_path):
                        st.success(f"æˆåŠŸå¤„ç†: {uploaded_file.name}")
                        success = True
                    else:
                        st.error(f"å¤„ç†å¤±è´¥: {uploaded_file.name}")
                    os.remove(temp_path)

            if success:
                st.session_state.documents_loaded = True
                st.success("æ–‡æ¡£å·²å‡†å¤‡å°±ç»ªï¼ç°åœ¨ä½ å¯ä»¥è¯¢é—®æœ‰å…³å®ƒä»¬çš„é—®é¢˜äº†ã€‚")

    if st.session_state.documents_loaded:
        for msg in st.session_state.chat_history:
            with st.chat_message("user"): st.write(msg[0])
            with st.chat_message("assistant"): st.write(msg[1])

        user_input = st.chat_input("è¯¢é—®æœ‰å…³æ–‡æ¡£çš„é—®é¢˜...")
        if user_input:
            with st.chat_message("user"):
                st.write(user_input)
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                try:
                    reranked_chunks = perform_search(query=user_input)
                    if not reranked_chunks or len(reranked_chunks) == 0:
                        logger.info("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚åˆ‡æ¢åˆ°æœ¬åœ°LLMã€‚")
                        with st.spinner("ä½¿ç”¨å¸¸è¯†å›ç­”..."):
                            full_response = handle_fallback(user_input)
                            if full_response.startswith("æŠ±æ­‰"):
                                st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ä¸”å¤‡ç”¨å›ç­”å¤±è´¥ã€‚")
                            else:
                                st.info("åŸºäºå¸¸è¯†å›ç­”ã€‚")
                    else:
                        formatted_messages = [
                            {"role": "user" if i % 2 == 0 else "assistant", "content": msg}
                            for i, msg in enumerate([m for pair in st.session_state.chat_history for m in pair])
                            if msg
                        ]

                        response_stream = rag(
                            prompt=user_input,
                            system_prompt=RAG_SYSTEM_PROMPT,
                            search=hybrid_search,
                            messages=formatted_messages,
                            max_contexts=5,
                            config=st.session_state.my_config
                        )

                        full_response = ""
                        for chunk in response_stream:
                            full_response += chunk
                            message_placeholder.markdown(full_response + "â–Œ")

                    message_placeholder.markdown(full_response)
                    st.session_state.chat_history.append((user_input, full_response))

                except Exception as e:
                    logger.error(f"é”™è¯¯: {str(e)}")
                    st.error(f"é”™è¯¯: {str(e)}")
    else:
        st.info(
            "è¯·é…ç½®ä½ çš„æ¨¡å‹è·¯å¾„å¹¶ä¸Šä¼ æ–‡æ¡£ä»¥å¼€å§‹ä½¿ç”¨ã€‚"
            if not st.session_state.my_config
            else "è¯·ä¸Šä¼ ä¸€äº›æ–‡æ¡£ä»¥å¼€å§‹ä½¿ç”¨ã€‚"
        )


if __name__ == "__main__":
    main()