import os
from typing import List, Dict, Any, Literal, Optional
from dataclasses import dataclass
import streamlit as st
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Qdrant
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
import tempfile
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from langchain.schema import HumanMessage
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain import hub
from langgraph.prebuilt import create_react_agent
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.language_models import BaseLanguageModel
from langchain.prompts import ChatPromptTemplate
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams


def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡"""
    if 'openai_api_key' not in st.session_state:
        st.session_state.openai_api_key = ""
    if 'qdrant_url' not in st.session_state:
        st.session_state.qdrant_url = ""
    if 'qdrant_api_key' not in st.session_state:
        st.session_state.qdrant_api_key = ""
    if 'embeddings' not in st.session_state:
        st.session_state.embeddings = None
    if 'llm' not in st.session_state:
        st.session_state.llm = None
    if 'databases' not in st.session_state:
        st.session_state.databases = {}


init_session_state()

DatabaseType = Literal["products", "support", "finance"]
PERSIST_DIRECTORY = "db_storage"


@dataclass
class CollectionConfig:
    name: str
    description: str
    collection_name: str  # è¿™å°†ç”¨ä½œQdranté›†åˆåç§°


# é›†åˆé…ç½®
COLLECTIONS: Dict[DatabaseType, CollectionConfig] = {
    "products": CollectionConfig(
        name="äº§å“ä¿¡æ¯",
        description="äº§å“è¯¦æƒ…ã€è§„æ ¼å’Œç‰¹æ€§",
        collection_name="products_collection"
    ),
    "support": CollectionConfig(
        name="å®¢æˆ·æ”¯æŒä¸FAQ",
        description="å®¢æˆ·æ”¯æŒä¿¡æ¯ã€å¸¸è§é—®é¢˜å’ŒæŒ‡å—",
        collection_name="support_collection"
    ),
    "finance": CollectionConfig(
        name="è´¢åŠ¡ä¿¡æ¯",
        description="è´¢åŠ¡æ•°æ®ã€æ”¶å…¥ã€æˆæœ¬å’Œè´Ÿå€º",
        collection_name="finance_collection"
    )
}


def initialize_models():
    """åˆå§‹åŒ–OpenAIæ¨¡å‹å’ŒQdrantå®¢æˆ·ç«¯"""
    if (st.session_state.openai_api_key and
            st.session_state.qdrant_url and
            st.session_state.qdrant_api_key):

        os.environ["OPENAI_API_KEY"] = st.session_state.openai_api_key
        st.session_state.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        st.session_state.llm = ChatOpenAI(temperature=0)

        try:
            client = QdrantClient(
                url=st.session_state.qdrant_url,
                api_key=st.session_state.qdrant_api_key
            )

            # æµ‹è¯•è¿æ¥
            client.get_collections()
            vector_size = 1536  # text-embedding-3-smallçš„å‘é‡å¤§å°
            st.session_state.databases = {}
            for db_type, config in COLLECTIONS.items():
                try:
                    client.get_collection(config.collection_name)
                except Exception:
                    # å¦‚æœé›†åˆä¸å­˜åœ¨åˆ™åˆ›å»º
                    client.create_collection(
                        collection_name=config.collection_name,
                        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)
                    )

                st.session_state.databases[db_type] = Qdrant(
                    client=client,
                    collection_name=config.collection_name,
                    embeddings=st.session_state.embeddings
                )

            return True
        except Exception as e:
            st.error(f"è¿æ¥Qdrantå¤±è´¥: {str(e)}")
            return False
    return False


def process_document(file) -> List[Document]:
    """å¤„ç†ä¸Šä¼ çš„PDFæ–‡æ¡£"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(file.getvalue())
            tmp_path = tmp_file.name

        loader = PyPDFLoader(tmp_path)
        documents = loader.load()

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_path)

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        texts = text_splitter.split_documents(documents)

        return texts
    except Exception as e:
        st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {e}")
        return []


def create_routing_agent() -> Agent:
    """ä½¿ç”¨agnoæ¡†æ¶åˆ›å»ºè·¯ç”±ä»£ç†"""
    return Agent(
        model=OpenAIChat(
            id="gpt-4o",
            api_key=st.session_state.openai_api_key
        ),
        tools=[],
        description="""ä½ æ˜¯ä¸€åæŸ¥è¯¢è·¯ç”±ä¸“å®¶ã€‚ä½ çš„å”¯ä¸€å·¥ä½œæ˜¯åˆ†æé—®é¢˜å¹¶ç¡®å®šå®ƒä»¬åº”è¯¥è¢«è·¯ç”±åˆ°å“ªä¸ªæ•°æ®åº“ã€‚
        ä½ å¿…é¡»å‡†ç¡®åœ°è¿”å›ä»¥ä¸‹ä¸‰ä¸ªé€‰é¡¹ä¹‹ä¸€ï¼š'products'ã€'support'æˆ–'finance'ã€‚ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š{question}""",
        instructions=[
            "ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š",
            "1. å…³äºäº§å“ã€åŠŸèƒ½ã€è§„æ ¼ã€ç‰©å“ç»†èŠ‚æˆ–äº§å“æ‰‹å†Œçš„é—®é¢˜ â†’ è¿”å›'products'",
            "2. å…³äºå¸®åŠ©ã€æŒ‡å¯¼ã€æ•…éšœæ’é™¤ã€å®¢æˆ·æœåŠ¡ã€FAQæˆ–æŒ‡å—çš„é—®é¢˜ â†’ è¿”å›'support'",
            "3. å…³äºæˆæœ¬ã€æ”¶å…¥ã€å®šä»·ã€è´¢åŠ¡æ•°æ®æˆ–è´¢åŠ¡æŠ¥å‘Šå’ŒæŠ•èµ„çš„é—®é¢˜ â†’ è¿”å›'finance'",
            "4. åªè¿”å›æ•°æ®åº“åç§°ï¼Œä¸è¦å…¶ä»–æ–‡æœ¬æˆ–è§£é‡Š",
            "5. å¦‚æœä½ å¯¹è·¯ç”±ä¸ç¡®å®šï¼Œè¿”å›ç©ºå“åº”"
        ],
        markdown=False,
        show_tool_calls=False
    )


def route_query(question: str) -> Optional[DatabaseType]:
    """é€šè¿‡æœç´¢æ‰€æœ‰æ•°æ®åº“å¹¶æ¯”è¾ƒç›¸å…³æ€§åˆ†æ•°æ¥è·¯ç”±æŸ¥è¯¢ã€‚
    å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æ•°æ®åº“ï¼Œè¿”å›Noneã€‚"""
    try:
        best_score = -1
        best_db_type = None
        all_scores = {}  # å­˜å‚¨æ‰€æœ‰åˆ†æ•°ç”¨äºè°ƒè¯•

        # æœç´¢æ¯ä¸ªæ•°æ®åº“å¹¶æ¯”è¾ƒç›¸å…³æ€§åˆ†æ•°
        for db_type, db in st.session_state.databases.items():
            results = db.similarity_search_with_score(
                question,
                k=3
            )

            if results:
                avg_score = sum(score for _, score in results) / len(results)
                all_scores[db_type] = avg_score

                if avg_score > best_score:
                    best_score = avg_score
                    best_db_type = db_type

        confidence_threshold = 0.5
        if best_score >= confidence_threshold and best_db_type:
            st.success(f"ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦è·¯ç”±: {best_db_type} (ç½®ä¿¡åº¦: {best_score:.3f})")
            return best_db_type

        st.warning(f"ä½ç½®ä¿¡åº¦åˆ†æ•°(ä½äº{confidence_threshold})ï¼Œé€€å›åˆ°LLMè·¯ç”±")

        # é€€å›åˆ°LLMè·¯ç”±
        routing_agent = create_routing_agent()
        response = routing_agent.run(question)

        db_type = (response.content
                   .strip()
                   .lower()
                   .translate(str.maketrans('', '', '`\'"')))

        if db_type in COLLECTIONS:
            st.success(f"ä½¿ç”¨LLMè·¯ç”±å†³ç­–: {db_type}")
            return db_type

        st.warning("æœªæ‰¾åˆ°åˆé€‚çš„æ•°æ®åº“ï¼Œå°†ä½¿ç”¨ç½‘ç»œæœç´¢ä½œä¸ºåå¤‡")
        return None

    except Exception as e:
        st.error(f"è·¯ç”±é”™è¯¯: {str(e)}")
        return None


def create_fallback_agent(chat_model: BaseLanguageModel):
    """åˆ›å»ºç”¨äºç½‘ç»œç ”ç©¶çš„LangGraphä»£ç†ã€‚"""

    def web_research(query: str) -> str:
        """å¸¦ç»“æœæ ¼å¼åŒ–çš„ç½‘ç»œæœç´¢ã€‚"""
        try:
            search = DuckDuckGoSearchRun(num_results=5)
            results = search.run(query)
            return results
        except Exception as e:
            return f"æœç´¢å¤±è´¥: {str(e)}ã€‚åŸºäºä¸€èˆ¬çŸ¥è¯†æä¾›ç­”æ¡ˆã€‚"

    tools = [web_research]

    agent = create_react_agent(model=chat_model,
                               tools=tools,
                               debug=False)

    return agent


def query_database(db: Qdrant, question: str) -> tuple[str, list]:
    """æŸ¥è¯¢æ•°æ®åº“å¹¶è¿”å›ç­”æ¡ˆå’Œç›¸å…³æ–‡æ¡£"""
    try:
        retriever = db.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 4}
        )

        relevant_docs = retriever.get_relevant_documents(question)

        if relevant_docs:
            # ä½¿ç”¨æ›´ç®€å•çš„é“¾åˆ›å»ºæ–¹å¼å’Œhubæç¤º
            retrieval_qa_prompt = ChatPromptTemplate.from_messages([
                ("system", """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ï¼Œæ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚
                             å›ç­”æ—¶å§‹ç»ˆä¿æŒç›´æ¥å’Œç®€æ´ã€‚
                             å¦‚æœä¸Šä¸‹æ–‡æ²¡æœ‰åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯æ¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œè¯·æ‰¿è®¤è¿™ä¸€é™åˆ¶ã€‚
                             ä¸¥æ ¼åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡å›ç­”ï¼Œé¿å…åšå‡ºå‡è®¾ã€‚"""),
                ("human", "ä»¥ä¸‹æ˜¯ä¸Šä¸‹æ–‡:\n{context}"),
                ("human", "é—®é¢˜: {input}"),
                ("assistant", "æˆ‘å°†æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å¸®åŠ©å›ç­”ä½ çš„é—®é¢˜ã€‚"),
                ("human", "è¯·æä¾›ä½ çš„ç­”æ¡ˆ:"),
            ])
            combine_docs_chain = create_stuff_documents_chain(st.session_state.llm, retrieval_qa_prompt)
            retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)

            response = retrieval_chain.invoke({"input": question})
            return response['answer'], relevant_docs

        raise ValueError("åœ¨æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

    except Exception as e:
        st.error(f"é”™è¯¯: {str(e)}")
        return "æˆ‘é‡åˆ°äº†ä¸€ä¸ªé”™è¯¯ã€‚è¯·å°è¯•é‡æ–°è¡¨è¿°ä½ çš„é—®é¢˜ã€‚", []


def _handle_web_fallback(question: str) -> tuple[str, list]:
    st.info("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚æ­£åœ¨æœç´¢ç½‘ç»œ...")
    fallback_agent = create_fallback_agent(st.session_state.llm)

    with st.spinner('ç ”ç©¶ä¸­...'):
        agent_input = {
            "messages": [
                HumanMessage(content=f"ç ”ç©¶å¹¶ä¸ºä»¥ä¸‹å†…å®¹æä¾›è¯¦ç»†ç­”æ¡ˆ: '{question}'")
            ],
            "is_last_step": False
        }

        try:
            response = fallback_agent.invoke(agent_input, config={"recursion_limit": 100})
            if isinstance(response, dict) and "messages" in response:
                answer = response["messages"][-1].content
                return f"ç½‘ç»œæœç´¢ç»“æœ:\n{answer}", []

        except Exception:
            # é€€å›åˆ°ä¸€èˆ¬LLMå“åº”
            fallback_response = st.session_state.llm.invoke(question).content
            return f"ç½‘ç»œæœç´¢ä¸å¯ç”¨ã€‚ä¸€èˆ¬å“åº”: {fallback_response}", []


def main():
    """ä¸»åº”ç”¨å‡½æ•°ã€‚"""
    st.set_page_config(page_title="å¸¦æ•°æ®åº“è·¯ç”±çš„RAGä»£ç†", page_icon="ğŸ“š")
    st.title("ğŸ“  å¸¦æ•°æ®åº“è·¯ç”±çš„RAGä»£ç†")

    # ç”¨äºAPIå¯†é’¥å’Œé…ç½®çš„ä¾§è¾¹æ 
    with st.sidebar:
        st.header("é…ç½®")

        # OpenAI APIå¯†é’¥
        api_key = st.text_input(
            "è¾“å…¥OpenAI APIå¯†é’¥:",
            type="password",
            value=st.session_state.openai_api_key,
            key="api_key_input"
        )

        # Qdranté…ç½®
        qdrant_url = st.text_input(
            "è¾“å…¥Qdrant URL:",
            value=st.session_state.qdrant_url,
            help="ç¤ºä¾‹: https://your-cluster.qdrant.tech"
        )

        qdrant_api_key = st.text_input(
            "è¾“å…¥Qdrant APIå¯†é’¥:",
            type="password",
            value=st.session_state.qdrant_api_key
        )

        # æ›´æ–°ä¼šè¯çŠ¶æ€
        if api_key:
            st.session_state.openai_api_key = api_key
        if qdrant_url:
            st.session_state.qdrant_url = qdrant_url
        if qdrant_api_key:
            st.session_state.qdrant_api_key = qdrant_api_key

        # å¦‚æœæä¾›äº†æ‰€æœ‰å‡­æ®ï¼Œåˆ™åˆå§‹åŒ–æ¨¡å‹
        if (st.session_state.openai_api_key and
                st.session_state.qdrant_url and
                st.session_state.qdrant_api_key):
            if initialize_models():
                st.success("æˆåŠŸè¿æ¥åˆ°OpenAIå’ŒQdrant!")
            else:
                st.error("åˆå§‹åŒ–å¤±è´¥ã€‚è¯·æ£€æŸ¥ä½ çš„å‡­æ®ã€‚")
        else:
            st.warning("è¯·è¾“å…¥æ‰€æœ‰å¿…è¦çš„å‡­æ®ä»¥ç»§ç»­")
            st.stop()

        st.markdown("---")

    st.header("æ–‡æ¡£ä¸Šä¼ ")
    st.info("ä¸Šä¼ æ–‡æ¡£ä»¥å¡«å……æ•°æ®åº“ã€‚æ¯ä¸ªæ ‡ç­¾å¯¹åº”ä¸åŒçš„æ•°æ®åº“ã€‚")
    tabs = st.tabs([collection_config.name for collection_config in COLLECTIONS.values()])

    for (collection_type, collection_config), tab in zip(COLLECTIONS.items(), tabs):
        with tab:
            st.write(collection_config.description)
            uploaded_files = st.file_uploader(
                f"ä¸Šä¼ PDFæ–‡æ¡£åˆ°{collection_config.name}",
                type="pdf",
                key=f"upload_{collection_type}",
                accept_multiple_files=True  # å…è®¸ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
            )

            if uploaded_files:
                with st.spinner('å¤„ç†æ–‡æ¡£ä¸­...'):
                    all_texts = []
                    for uploaded_file in uploaded_files:
                        texts = process_document(uploaded_file)
                        all_texts.extend(texts)

                    if all_texts:
                        db = st.session_state.databases[collection_type]
                        db.add_documents(all_texts)
                        st.success("æ–‡æ¡£å·²å¤„ç†å¹¶æ·»åŠ åˆ°æ•°æ®åº“!")

    # æŸ¥è¯¢éƒ¨åˆ†
    st.header("æé—®")
    st.info("åœ¨ä¸‹æ–¹è¾“å…¥ä½ çš„é—®é¢˜ï¼Œä»ç›¸å…³æ•°æ®åº“ä¸­æŸ¥æ‰¾ç­”æ¡ˆã€‚")
    question = st.text_input("è¾“å…¥ä½ çš„é—®é¢˜:")

    if question:
        with st.spinner('å¯»æ‰¾ç­”æ¡ˆä¸­...'):
            # è·¯ç”±é—®é¢˜
            collection_type = route_query(question)

            if collection_type is None:
                # ç›´æ¥ä½¿ç”¨ç½‘ç»œæœç´¢åå¤‡
                answer, relevant_docs = _handle_web_fallback(question)
                st.write("### ç­”æ¡ˆ(æ¥è‡ªç½‘ç»œæœç´¢)")
                st.write(answer)
            else:
                # æ˜¾ç¤ºè·¯ç”±ä¿¡æ¯å¹¶æŸ¥è¯¢æ•°æ®åº“
                st.info(f"å°†é—®é¢˜è·¯ç”±åˆ°: {COLLECTIONS[collection_type].name}")
                db = st.session_state.databases[collection_type]
                answer, relevant_docs = query_database(db, question)
                st.write("### ç­”æ¡ˆ")
                st.write(answer)


if __name__ == "__main__":
    main()