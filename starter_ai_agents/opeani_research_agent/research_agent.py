import os
import uuid
import asyncio
import streamlit as st
from datetime import datetime
from dotenv import load_dotenv

from agents import (
    Agent,
    Runner,
    WebSearchTool,
    function_tool,
    handoff,
    trace,
)

from pydantic import BaseModel

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="OpenAI ç ”ç©¶åŠ©æ‰‹æ™ºèƒ½ä½“",
    page_icon="ğŸ“°",
    layout="wide",  # å®½å±å¸ƒå±€
    initial_sidebar_state="expanded"  # ä¾§è¾¹æ é»˜è®¤å±•å¼€
)

# ç¡®ä¿APIå¯†é’¥å·²é…ç½®
if not os.environ.get("OPENAI_API_KEY"):
    st.error("è¯·è®¾ç½®æ‚¨çš„ OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    st.stop()  # åœæ­¢é¡µé¢è¿è¡Œ

# åº”ç”¨æ ‡é¢˜ä¸æè¿°
st.title("ğŸ“° OpenAI ç ”ç©¶åŠ©æ‰‹æ™ºèƒ½ä½“")
st.subheader("ç”± OpenAI Agents SDK æä¾›æ”¯æŒ")
st.markdown("""
æœ¬åº”ç”¨é€šè¿‡åˆ›å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå±•ç¤º OpenAI Agents SDK çš„èƒ½åŠ›ï¼Œ
è¯¥ç³»ç»Ÿå¯ç ”ç©¶æ–°é—»ä¸»é¢˜å¹¶ç”Ÿæˆå…¨é¢çš„ç ”ç©¶æŠ¥å‘Šã€‚
""")


# å®šä¹‰æ•°æ®æ¨¡å‹
class ResearchPlan(BaseModel):
    topic: str  # ç ”ç©¶ä¸»é¢˜
    search_queries: list[str]  # æœç´¢æŸ¥è¯¢åˆ—è¡¨
    focus_areas: list[str]  # é‡ç‚¹ç ”ç©¶é¢†åŸŸåˆ—è¡¨


class ResearchReport(BaseModel):
    title: str  # æŠ¥å‘Šæ ‡é¢˜
    outline: list[str]  # æŠ¥å‘Šå¤§çº²
    report: str  # æŠ¥å‘Šæ­£æ–‡
    sources: list[str]  # ä¿¡æ¯æ¥æºåˆ—è¡¨
    word_count: int  # æŠ¥å‘Šå­—æ•°


# ç”¨äºä¿å­˜ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç°çš„äº‹å®çš„è‡ªå®šä¹‰å·¥å…·
@function_tool
def save_important_fact(fact: str, source: str = None) -> str:
    """ä¿å­˜ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç°çš„é‡è¦äº‹å®ã€‚

    å‚æ•°:
        fact: éœ€ä¿å­˜çš„é‡è¦äº‹å®
        source: äº‹å®çš„å¯é€‰æ¥æº

    è¿”å›:
        ç¡®è®¤ä¿¡æ¯
    """
    if "collected_facts" not in st.session_state:
        st.session_state.collected_facts = []  # åˆå§‹åŒ–äº‹å®å­˜å‚¨åˆ—è¡¨

    st.session_state.collected_facts.append({
        "fact": fact,
        "source": source or "æœªæŒ‡å®š",  # è‹¥æœªæä¾›æ¥æºåˆ™æ˜¾ç¤º"æœªæŒ‡å®š"
        "timestamp": datetime.now().strftime("%H:%M:%S")  # è®°å½•äº‹å®ä¿å­˜æ—¶é—´
    })

    return f"äº‹å®å·²ä¿å­˜: {fact}"


# å®šä¹‰æ™ºèƒ½ä½“
research_agent = Agent(
    name="ç ”ç©¶æ™ºèƒ½ä½“",
    instructions="ä½ æ˜¯ä¸€åç ”ç©¶åŠ©æ‰‹ã€‚ç»™å®šæœç´¢å…³é”®è¯åï¼Œéœ€é€šè¿‡ç½‘ç»œæœç´¢è¯¥å…³é”®è¯å¹¶"
                 "ç”Ÿæˆç»“æœçš„ç®€æ´æ‘˜è¦ã€‚æ‘˜è¦éœ€åŒ…å«2-3ä¸ªæ®µè½ï¼Œå­—æ•°æ§åˆ¶åœ¨300å­—ä»¥å†…ã€‚"
                 "éœ€æ•æ‰æ ¸å¿ƒè¦ç‚¹ï¼Œè¯­è¨€ç®€æ´ï¼ˆæ— éœ€å®Œæ•´å¥å­æˆ–è§„èŒƒè¯­æ³•ï¼‰ã€‚"
                 "è¯¥æ‘˜è¦å°†ä¾›æŠ¥å‘Šæ•´åˆäººå‘˜ä½¿ç”¨ï¼Œå› æ­¤åŠ¡å¿…æç‚¼ç²¾åã€å‰”é™¤æ— å…³å†…å®¹ã€‚"
                 "é™¤æ‘˜è¦æœ¬èº«å¤–ï¼Œä¸å¾—åŒ…å«ä»»ä½•é¢å¤–è¯„è®ºã€‚",
    model="gpt-4o-mini",  # ä½¿ç”¨çš„æ¨¡å‹
    tools=[
        WebSearchTool(),  # ç½‘ç»œæœç´¢å·¥å…·
        save_important_fact  # äº‹å®ä¿å­˜å·¥å…·
    ],
)

editor_agent = Agent(
    name="ç¼–è¾‘æ™ºèƒ½ä½“",
    handoff_description="è´Ÿè´£æ’°å†™å…¨é¢ç ”ç©¶æŠ¥å‘Šçš„é«˜çº§ç ”ç©¶å‘˜",
    instructions="ä½ æ˜¯ä¸€åé«˜çº§ç ”ç©¶å‘˜ï¼Œè´Ÿè´£ä¸ºç ”ç©¶éœ€æ±‚æ’°å†™ç»“æ„å®Œæ•´çš„æŠ¥å‘Šã€‚"
                 "ä½ å°†æ”¶åˆ°åŸå§‹ç ”ç©¶éœ€æ±‚åŠç ”ç©¶åŠ©æ‰‹å®Œæˆçš„åˆæ­¥ç ”ç©¶å†…å®¹ã€‚\n"
                 "é¦–å…ˆéœ€ä¸ºæŠ¥å‘Šåˆ¶å®šå¤§çº²ï¼Œæ˜ç¡®æŠ¥å‘Šçš„ç»“æ„ä¸é€»è¾‘æµç¨‹ã€‚"
                 "ç„¶åç”Ÿæˆå®Œæ•´æŠ¥å‘Šä½œä¸ºæœ€ç»ˆè¾“å‡ºã€‚\n"
                 "æœ€ç»ˆè¾“å‡ºéœ€é‡‡ç”¨Markdownæ ¼å¼ï¼Œå†…å®¹éœ€è¯¦å®æ·±å…¥ï¼Œç›®æ ‡é•¿åº¦ä¸º5-10é¡µï¼Œ"
                 "å­—æ•°è‡³å°‘1000å­—ã€‚",
    model="gpt-4o-mini",
    output_type=ResearchReport,  # è¾“å‡ºç±»å‹ä¸ºResearchReportæ¨¡å‹
)

triage_agent = Agent(
    name="è°ƒåº¦æ™ºèƒ½ä½“",
    instructions="""ä½ æ˜¯æœ¬æ¬¡ç ”ç©¶ä»»åŠ¡çš„åè°ƒè€…ã€‚ä¸»è¦èŒè´£åŒ…æ‹¬ï¼š
    1. ç†è§£ç”¨æˆ·æå‡ºçš„ç ”ç©¶ä¸»é¢˜
    2. åˆ¶å®šç ”ç©¶è®¡åˆ’ï¼ŒåŒ…å«ä»¥ä¸‹è¦ç´ ï¼š
       - topic: æ¸…æ™°çš„ç ”ç©¶ä¸»é¢˜è¡¨è¿°
       - search_queries: 3-5ä¸ªç”¨äºæ”¶é›†ä¿¡æ¯çš„å…·ä½“æœç´¢æŸ¥è¯¢
       - focus_areas: 3-5ä¸ªéœ€æ·±å…¥ç ”ç©¶çš„ä¸»é¢˜å…³é”®æ–¹å‘
    3. å°†ä»»åŠ¡ç§»äº¤è‡³ç ”ç©¶æ™ºèƒ½ä½“ä»¥æ”¶é›†ä¿¡æ¯
    4. ç ”ç©¶å®Œæˆåï¼Œå°†ä»»åŠ¡ç§»äº¤è‡³ç¼–è¾‘æ™ºèƒ½ä½“æ’°å†™å…¨é¢æŠ¥å‘Š

    è¯·ç¡®ä¿ç ”ç©¶è®¡åˆ’ä»¥æŒ‡å®šæ ¼å¼å‘ˆç°ï¼ŒåŒ…å«topicã€search_querieså’Œfocus_areasä¸‰ä¸ªéƒ¨åˆ†ã€‚
    """,
    handoffs=[
        handoff(research_agent),  # ç§»äº¤è‡³ç ”ç©¶æ™ºèƒ½ä½“
        handoff(editor_agent)  # ç§»äº¤è‡³ç¼–è¾‘æ™ºèƒ½ä½“
    ],
    model="gpt-4o-mini",
    output_type=ResearchPlan,  # è¾“å‡ºç±»å‹ä¸ºResearchPlanæ¨¡å‹
)

# åˆ›å»ºç”¨äºè¾“å…¥å’Œæ§åˆ¶çš„ä¾§è¾¹æ 
with st.sidebar:
    st.header("ç ”ç©¶ä¸»é¢˜")
    user_topic = st.text_input(
        "è¾“å…¥éœ€ç ”ç©¶çš„ä¸»é¢˜ï¼š",
    )

    # å¼€å§‹ç ”ç©¶æŒ‰é’®ï¼ˆæ— ä¸»é¢˜æ—¶ç¦ç”¨ï¼‰
    start_button = st.button("å¼€å§‹ç ”ç©¶", type="primary", disabled=not user_topic)

    st.divider()  # åˆ†éš”çº¿
    st.subheader("ç¤ºä¾‹ä¸»é¢˜")
    example_topics = [
        "å¯¹äºä»æœªä¹˜åè¿‡é‚®è½®çš„é¦–æ¬¡æ—…è¡Œè€…ï¼Œç¾å›½æœ€ä½³é‚®è½®å…¬å¸æœ‰å“ªäº›ï¼Ÿ",
        "å¯¹äºæƒ³ä»æ³•å¼å‹æ»¤å£¶å‡çº§çš„ç”¨æˆ·ï¼Œæœ€ä½³é«˜æ€§ä»·æ¯”æ„å¼æµ“ç¼©å’–å•¡æœºæœ‰å“ªäº›ï¼Ÿ",
        "å¯¹äºé¦–æ¬¡ç‹¬è‡ªæ—…è¡Œçš„äººï¼Œå°åº¦æœ€ä½³å°ä¼—æ—…è¡Œç›®çš„åœ°æœ‰å“ªäº›ï¼Ÿ"
    ]

    # ç¤ºä¾‹ä¸»é¢˜æŒ‰é’®ï¼ˆç‚¹å‡»åè‡ªåŠ¨å¡«å……è‡³è¾“å…¥æ¡†ï¼‰
    for topic in example_topics:
        if st.button(topic):
            user_topic = topic
            start_button = True

# ä¸»å†…å®¹åŒºï¼ˆåŒ…å«ä¸¤ä¸ªæ ‡ç­¾é¡µï¼‰
tab1, tab2 = st.tabs(["ç ”ç©¶è¿‡ç¨‹", "æŠ¥å‘Š"])

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ä»¥å­˜å‚¨ç»“æœ
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = str(uuid.uuid4().hex[:16])  # ç”Ÿæˆå”¯ä¸€ä¼šè¯ID
if "collected_facts" not in st.session_state:
    st.session_state.collected_facts = []  # å­˜å‚¨æ”¶é›†åˆ°çš„äº‹å®
if "research_done" not in st.session_state:
    st.session_state.research_done = False  # ç ”ç©¶å®ŒæˆçŠ¶æ€æ ‡è®°
if "report_result" not in st.session_state:
    st.session_state.report_result = None  # å­˜å‚¨æŠ¥å‘Šç»“æœ


# ä¸»ç ”ç©¶å‡½æ•°ï¼ˆå¼‚æ­¥ï¼‰
async def run_research(topic):
    # é‡ç½®æ–°ç ”ç©¶çš„çŠ¶æ€
    st.session_state.collected_facts = []
    st.session_state.research_done = False
    st.session_state.report_result = None

    with tab1:
        message_container = st.container()  # ç”¨äºæ˜¾ç¤ºç ”ç©¶è¿‡ç¨‹çš„å®¹å™¨

    # åˆ›å»ºé”™è¯¯å¤„ç†å®¹å™¨
    error_container = st.empty()

    # ä¸ºæ•´ä¸ªå·¥ä½œæµç¨‹åˆ›å»ºè·Ÿè¸ªè®°å½•
    with trace("æ–°é—»ç ”ç©¶", group_id=st.session_state.conversation_id):
        # è°ƒåº¦æ™ºèƒ½ä½“é˜¶æ®µ
        with message_container:
            st.write("ğŸ” **è°ƒåº¦æ™ºèƒ½ä½“**ï¼šæ­£åœ¨åˆ¶å®šç ”ç©¶æ–¹æ¡ˆ...")

        triage_result = await Runner.run(
            triage_agent,
            f"æ·±å…¥ç ”ç©¶ä»¥ä¸‹ä¸»é¢˜ï¼š{topic}ã€‚ç ”ç©¶ç»“æœå°†ç”¨äºç”Ÿæˆå…¨é¢çš„ç ”ç©¶æŠ¥å‘Šã€‚"
        )

        # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºResearchPlanå¯¹è±¡æˆ–å­—ç¬¦ä¸²
        if hasattr(triage_result.final_output, 'topic'):
            research_plan = triage_result.final_output
            plan_display = {
                "topic": research_plan.topic,
                "search_queries": research_plan.search_queries,
                "focus_areas": research_plan.focus_areas
            }
        else:
            # è‹¥æœªè·å–åˆ°é¢„æœŸè¾“å‡ºç±»å‹ï¼Œåˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            research_plan = {
                "topic": topic,
                "search_queries": [f"ç ”ç©¶ {topic}"],
                "focus_areas": [f"{topic} çš„ä¸€èˆ¬ä¿¡æ¯"]
            }
            plan_display = research_plan

        with message_container:
            st.write("ğŸ“‹ **ç ”ç©¶è®¡åˆ’**ï¼š")
            st.json(plan_display)  # ä»¥JSONæ ¼å¼æ˜¾ç¤ºç ”ç©¶è®¡åˆ’

        # å®æ—¶æ˜¾ç¤ºæ”¶é›†åˆ°çš„äº‹å®
        fact_placeholder = message_container.empty()

        # å®šæœŸæ£€æŸ¥æ–°äº‹å®ï¼ˆå¢åŠ æ£€æŸ¥æ¬¡æ•°ä»¥ç¡®ä¿ç ”ç©¶å…¨é¢æ€§ï¼‰
        previous_fact_count = 0
        for i in range(15):
            current_facts = len(st.session_state.collected_facts)
            if current_facts > previous_fact_count:
                with fact_placeholder.container():
                    st.write("ğŸ“š **å·²æ”¶é›†äº‹å®**ï¼š")
                    for fact in st.session_state.collected_facts:
                        st.info(f"**äº‹å®**ï¼š{fact['fact']}\n\n**æ¥æº**ï¼š{fact['source']}")
                previous_fact_count = current_facts
            await asyncio.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡

        # ç¼–è¾‘æ™ºèƒ½ä½“é˜¶æ®µ
        with message_container:
            st.write("ğŸ“ **ç¼–è¾‘æ™ºèƒ½ä½“**ï¼šæ­£åœ¨ç”Ÿæˆå…¨é¢ç ”ç©¶æŠ¥å‘Š...")

        try:
            report_result = await Runner.run(
                editor_agent,
                triage_result.to_input_list()  # å°†è°ƒåº¦ç»“æœè½¬æ¢ä¸ºè¾“å…¥åˆ—è¡¨
            )

            st.session_state.report_result = report_result.final_output

            with message_container:
                st.write("âœ… **ç ”ç©¶å®Œæˆï¼æŠ¥å‘Šå·²ç”Ÿæˆã€‚**")

                # é¢„è§ˆæŠ¥å‘Šç‰‡æ®µ
                if hasattr(report_result.final_output, 'report'):
                    report_preview = report_result.final_output.report[:300] + "..."  # å–å‰300å­—ç¬¦
                else:
                    report_preview = str(report_result.final_output)[:300] + "..."

                st.write("ğŸ“„ **æŠ¥å‘Šé¢„è§ˆ**ï¼š")
                st.markdown(report_preview)
                st.write("*å®Œæ•´æŠ¥å‘Šè¯·æŸ¥çœ‹ã€ŒæŠ¥å‘Šã€æ ‡ç­¾é¡µã€‚*")

        except Exception as e:
            st.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™ï¼š{str(e)}")
            # è‹¥å‡ºé”™ï¼Œæ˜¾ç¤ºåŸå§‹æ™ºèƒ½ä½“å“åº”ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
            if hasattr(triage_result, 'new_items'):
                # ç­›é€‰åŒ…å«å†…å®¹çš„é¡¹ç›®
                messages = [item for item in triage_result.new_items if hasattr(item, 'content')]
                if messages:
                    raw_content = "\n\n".join([str(m.content) for m in messages if m.content])
                    st.session_state.report_result = raw_content

                    with message_container:
                        st.write("âš ï¸ **ç ”ç©¶å·²å®Œæˆï¼Œä½†ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Šæ—¶å‡ºç°é—®é¢˜ã€‚**")
                        st.write("åŸå§‹ç ”ç©¶ç»“æœå¯åœ¨ã€ŒæŠ¥å‘Šã€æ ‡ç­¾é¡µæŸ¥çœ‹ã€‚")

    st.session_state.research_done = True  # æ ‡è®°ç ”ç©¶å®Œæˆ


# ç‚¹å‡»å¼€å§‹æŒ‰é’®åæ‰§è¡Œç ”ç©¶
if start_button:
    with st.spinner(f"æ­£åœ¨ç ”ç©¶ï¼š{user_topic}"):  # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
        try:
            asyncio.run(run_research(user_topic))  # è¿è¡Œå¼‚æ­¥ç ”ç©¶å‡½æ•°
        except Exception as e:
            st.error(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
            # è®¾ç½®åŸºç¡€æŠ¥å‘Šç»“æœï¼Œç¡®ä¿ç”¨æˆ·è·å¾—åé¦ˆ
            st.session_state.report_result = f"# {user_topic} ç ”ç©¶æŠ¥å‘Š\n\nç ”ç©¶è¿‡ç¨‹ä¸­ä¸å¹¸å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•æˆ–æ›´æ¢ç ”ç©¶ä¸»é¢˜ã€‚\n\né”™è¯¯è¯¦æƒ…ï¼š{str(e)}"
            st.session_state.research_done = True

# åœ¨ã€ŒæŠ¥å‘Šã€æ ‡ç­¾é¡µæ˜¾ç¤ºç»“æœ
with tab2:
    if st.session_state.research_done and st.session_state.report_result:
        report = st.session_state.report_result

        # å¤„ç†ä¸åŒç±»å‹çš„æŠ¥å‘Šç»“æœ
        if hasattr(report, 'title'):
            # è‹¥ä¸ºç»“æ„åŒ–ResearchReportå¯¹è±¡
            title = report.title

            # è‹¥æœ‰å¤§çº²åˆ™æ˜¾ç¤ºï¼ˆé»˜è®¤å±•å¼€ï¼‰
            if hasattr(report, 'outline') and report.outline:
                with st.expander("æŠ¥å‘Šå¤§çº²", expanded=True):
                    for i, section in enumerate(report.outline):
                        st.markdown(f"{i + 1}. {section}")

            # è‹¥æœ‰å­—æ•°ç»Ÿè®¡åˆ™æ˜¾ç¤º
            if hasattr(report, 'word_count'):
                st.info(f"å­—æ•°ç»Ÿè®¡ï¼š{report.word_count}")

            # ä»¥Markdownæ ¼å¼æ˜¾ç¤ºå®Œæ•´æŠ¥å‘Š
            if hasattr(report, 'report'):
                report_content = report.report
                st.markdown(report_content)
            else:
                report_content = str(report)
                st.markdown(report_content)

            # è‹¥æœ‰æ¥æºåˆ—è¡¨åˆ™æ˜¾ç¤º
            if hasattr(report, 'sources') and report.sources:
                with st.expander("ä¿¡æ¯æ¥æº"):
                    for i, source in enumerate(report.sources):
                        st.markdown(f"{i + 1}. {source}")

            # æ·»åŠ æŠ¥å‘Šä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ä¸‹è½½æŠ¥å‘Š",
                data=report_content,
                file_name=f"{title.replace(' ', '_')}.md",  # æ–‡ä»¶åæ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿
                mime="text/markdown"  # æ–‡ä»¶ç±»å‹ä¸ºMarkdown
            )
        else:
            # å¤„ç†å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹çš„å“åº”
            report_content = str(report)
            title = user_topic.title()  # å°†ä¸»é¢˜é¦–å­—æ¯å¤§å†™ä½œä¸ºæ ‡é¢˜

            st.title(f"{title}")
            st.markdown(report_content)

            # æ·»åŠ æŠ¥å‘Šä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ä¸‹è½½æŠ¥å‘Š",
                data=report_content,
                file_name=f"{title.replace(' ', '_')}.md",
                mime="text/markdown"
            )