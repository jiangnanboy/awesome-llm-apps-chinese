import os
import json
import re
import sys
import io
import contextlib
import warnings
from typing import Optional, List, Any, Tuple
from PIL import Image
import streamlit as st
import pandas as pd
import base64
from io import BytesIO
from together import Together
from e2b_code_interpreter import Sandbox

# å¿½ç•¥pydanticæ¨¡å—çš„UserWarningè­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="pydantic")


# ç”¨äºåŒ¹é…pattern = re.compile(r"```python\n(.*?)\n```", re.DOTALL)

def code_interpret(e2b_code_interpreter: Sandbox, code: str) -> Optional[List[Any]]:
    with st.spinner('åœ¨E2Bæ²™ç®±ä¸­æ‰§è¡Œä»£ç ...'):
        stdout_capture = io.StringIO()
        stderr_capture = io.StringIO()

        with contextlib.redirect_stdout(stdout_capture), contextlib.redirect_stderr(stderr_capture):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                exec = e2b_code_interpreter.run_code(code)

        # è¾“å‡ºé”™è¯¯ä¿¡æ¯
        if stderr_capture.getvalue():
            print("[ä»£ç è§£é‡Šå™¨è­¦å‘Š/é”™è¯¯]", file=sys.stderr)
            print(stderr_capture.getvalue(), file=sys.stderr)

        # è¾“å‡ºæ ‡å‡†è¾“å‡ºä¿¡æ¯
        if stdout_capture.getvalue():
            print("[ä»£ç è§£é‡Šå™¨è¾“å‡º]", file=sys.stdout)
            print(stdout_capture.getvalue(), file=sys.stdout)

        # æ£€æŸ¥æ‰§è¡Œé”™è¯¯
        if exec.error:
            print(f"[ä»£ç è§£é‡Šå™¨é”™è¯¯] {exec.error}", file=sys.stderr)
            return None
        return exec.results


def match_code_blocks(llm_response: str) -> str:
    match = pattern.search(llm_response)
    if match:
        code = match.group(1)
        return code
    return ""


def chat_with_llm(e2b_code_interpreter: Sandbox, user_message: str, dataset_path: str) -> Tuple[
    Optional[List[Any]], str]:
    # æ›´æ–°ç³»ç»Ÿæç¤ºä»¥åŒ…å«æ•°æ®é›†è·¯å¾„ä¿¡æ¯
    system_prompt = f"""ä½ æ˜¯ä¸€åPythonæ•°æ®ç§‘å­¦å®¶å’Œæ•°æ®å¯è§†åŒ–ä¸“å®¶ã€‚ä½ ä¼šæ”¶åˆ°ä¸€ä¸ªä½äº'{dataset_path}'è·¯å¾„çš„æ•°æ®é›†ä»¥åŠç”¨æˆ·çš„æŸ¥è¯¢ã€‚
ä½ éœ€è¦åˆ†æè¯¥æ•°æ®é›†å¹¶é€šè¿‡å“åº”å›ç­”ç”¨æˆ·çš„æŸ¥è¯¢ï¼ŒåŒæ—¶è¿è¡ŒPythonä»£ç æ¥è§£å†³é—®é¢˜ã€‚
é‡è¦æç¤ºï¼šè¯»å–CSVæ–‡ä»¶æ—¶ï¼Œè¯·åœ¨ä»£ç ä¸­å§‹ç»ˆä½¿ç”¨æ•°æ®é›†è·¯å¾„å˜é‡'{dataset_path}'ã€‚"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message},
    ]

    with st.spinner('ä»Together AIå¤§è¯­è¨€æ¨¡å‹è·å–å“åº”...'):
        client = Together(api_key=st.session_state.together_api_key)
        response = client.chat.completions.create(
            model=st.session_state.model_name,
            messages=messages,
        )

        response_message = response.choices[0].message
        python_code = match_code_blocks(response_message.content)

        if python_code:
            code_interpreter_results = code_interpret(e2b_code_interpreter, python_code)
            return code_interpreter_results, response_message.content
        else:
            st.warning(f"æœªèƒ½ä»æ¨¡å‹å“åº”ä¸­åŒ¹é…åˆ°ä»»ä½•Pythonä»£ç ")
            return None, response_message.content


def upload_dataset(code_interpreter: Sandbox, uploaded_file) -> str:
    dataset_path = f"./{uploaded_file.name}"

    try:
        code_interpreter.files.write(dataset_path, uploaded_file)
        return dataset_path
    except Exception as error:
        st.error(f"æ–‡ä»¶ä¸Šä¼ è¿‡ç¨‹ä¸­å‡ºé”™ï¼š{error}")
        raise error


def main():
    """ä¸»Streamlitåº”ç”¨ç¨‹åºã€‚"""
    st.title("ğŸ“Š AIæ•°æ®å¯è§†åŒ–åŠ©æ‰‹")
    st.write("ä¸Šä¼ ä½ çš„æ•°æ®é›†å¹¶æå‡ºç›¸å…³é—®é¢˜ï¼")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
    if 'together_api_key' not in st.session_state:
        st.session_state.together_api_key = ''
    if 'e2b_api_key' not in st.session_state:
        st.session_state.e2b_api_key = ''
    if 'model_name' not in st.session_state:
        st.session_state.model_name = ''

    with st.sidebar:
        st.header("APIå¯†é’¥å’Œæ¨¡å‹é…ç½®")
        st.session_state.together_api_key = st.sidebar.text_input("Together AI APIå¯†é’¥", type="password")
        st.sidebar.info("ğŸ’¡ æ¯ä¸ªäººéƒ½å¯ä»¥åœ¨Together AI - äººå·¥æ™ºèƒ½åŠ é€Ÿäº‘å¹³å°è·å¾—1ç¾å…ƒçš„å…è´¹é¢åº¦")
        st.sidebar.markdown("[è·å–Together AI APIå¯†é’¥](https://api.together.ai/signin)")

        st.session_state.e2b_api_key = st.sidebar.text_input("è¾“å…¥E2B APIå¯†é’¥", type="password")
        st.sidebar.markdown("[è·å–E2B APIå¯†é’¥](https://e2b.dev/docs/legacy/getting-started/api-key)")

        # æ·»åŠ æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
        model_options = {
            "Meta-Llama 3.1 405B": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
            "æ·±åº¦æ±‚ç´¢V3": "deepseek-ai/DeepSeek-V3",
            "é€šä¹‰åƒé—®2.5 7B": "Qwen/Qwen2.5-7B-Instruct-Turbo",
            "Meta-Llama 3.3 70B": "meta-llama/Llama-3.3-70B-Instruct-Turbo"
        }
        st.session_state.model_name = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=list(model_options.keys()),
            index=0  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªé€‰é¡¹
        )
        st.session_state.model_name = model_options[st.session_state.model_name]

    uploaded_file = st.file_uploader("é€‰æ‹©ä¸€ä¸ªCSVæ–‡ä»¶", type="csv")

    if uploaded_file is not None:
        # æ˜¾ç¤ºæ•°æ®é›†ï¼Œå¸¦åˆ‡æ¢é€‰é¡¹
        df = pd.read_csv(uploaded_file)
        st.write("æ•°æ®é›†ï¼š")
        show_full = st.checkbox("æ˜¾ç¤ºå®Œæ•´æ•°æ®é›†")
        if show_full:
            st.dataframe(df)
        else:
            st.write("é¢„è§ˆï¼ˆå‰5è¡Œï¼‰ï¼š")
            st.dataframe(df.head())
        # æŸ¥è¯¢è¾“å…¥
        query = st.text_area("ä½ æƒ³äº†è§£å…³äºä½ çš„æ•°æ®çš„å“ªäº›ä¿¡æ¯ï¼Ÿ",
                             "ä½ èƒ½æ¯”è¾ƒä¸åŒç±»åˆ«ä¹‹é—´ä¸¤äººçš„å¹³å‡è´¹ç”¨å—ï¼Ÿ")

        if st.button("åˆ†æ"):
            if not st.session_state.together_api_key or not st.session_state.e2b_api_key:
                st.error("è¯·åœ¨ä¾§è¾¹æ ä¸­è¾“å…¥ä¸¤ä¸ªAPIå¯†é’¥ã€‚")
            else:
                with Sandbox(api_key=st.session_state.e2b_api_key) as code_interpreter:
                    # ä¸Šä¼ æ•°æ®é›†
                    dataset_path = upload_dataset(code_interpreter, uploaded_file)

                    # å°†dataset_pathä¼ é€’ç»™chat_with_llm
                    code_results, llm_response = chat_with_llm(code_interpreter, query, dataset_path)

                    # æ˜¾ç¤ºå¤§è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬å“åº”
                    st.write("AIå“åº”ï¼š")
                    st.write(llm_response)

                    # æ˜¾ç¤ºç»“æœ/å¯è§†åŒ–å†…å®¹
                    if code_results:
                        for result in code_results:
                            if hasattr(result, 'png') and result.png:  # æ£€æŸ¥æ˜¯å¦æœ‰PNGæ•°æ®
                                # è§£ç base64ç¼–ç çš„PNGæ•°æ®
                                png_data = base64.b64decode(result.png)

                                # å°†PNGæ•°æ®è½¬æ¢ä¸ºå›¾åƒå¹¶æ˜¾ç¤º
                                image = Image.open(BytesIO(png_data))
                                st.image(image, caption="ç”Ÿæˆçš„å¯è§†åŒ–ç»“æœ", use_container_width=False)
                            elif hasattr(result, 'figure'):  # å¯¹äºmatplotlibå›¾è¡¨
                                fig = result.figure  # æå–matplotlibå›¾è¡¨
                                st.pyplot(fig)  # ä½¿ç”¨st.pyplotæ˜¾ç¤º
                            elif hasattr(result, 'show'):  # å¯¹äºplotlyå›¾è¡¨
                                st.plotly_chart(result)
                            elif isinstance(result, (pd.DataFrame, pd.Series)):
                                st.dataframe(result)
                            else:
                                st.write(result)


if __name__ == "__main__":
    main()